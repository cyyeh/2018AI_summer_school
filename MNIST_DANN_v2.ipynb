{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-DANN_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/cyyeh/2018AI_summer_school/blob/master/MNIST_DANN_v2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "JRKBYCdmZXwr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implement Domain-Adversarial Neural Networks (DANN)\n",
        "\n",
        "*** 先點擊 File -> Save a copy in Drive，並在Copy上繼續操作。\n",
        "\n",
        "\n",
        "Reference: \n",
        "\n",
        "https://arxiv.org/abs/1505.07818 (JMLR 2015 paper)\n",
        "\n",
        "https://github.com/pumpikano/tf-dann  (source code)\n",
        "\n",
        "https://www.tensorflow.org/\n",
        "\n",
        "![alt text](https://goo.gl/ivg4Q7)\n"
      ]
    },
    {
      "metadata": {
        "id": "84l9rkYL--DB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Get Ready\n",
        "\n",
        "確認檔案是否齊全，並定義工具函數。\n",
        "\n",
        "1.   以!wget下載所需要的檔案並用!ls列出，應有datalab, mnistm_data.pkl, DANN.png, MNIST_model.png。\n",
        "2.   定義之後會用到的函數，如：convolution, max pooling, shuffle...等。\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "kgWDezwbdKQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/e227qfod9b5f0ed/mnistm_data.pkl\n",
        "!wget https://www.dropbox.com/s/da5ukrtqlusex1z/MNIST_model.png\n",
        "!wget https://www.dropbox.com/s/77v4rase9pz4lv7/DANN.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02bOOYyBlEMM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### list files on workspace ###\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u0waWyILpGVE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### construct utilities ### \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "# Model construction utilities below adapted from\n",
        "# https://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html#deep-mnist-for-experts\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "\n",
        "def conv2d(x, W):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def shuffle_aligned_list(data):\n",
        "    \"\"\"Shuffle arrays in a list by shuffling each array identically.\"\"\"\n",
        "    num = data[0].shape[0]\n",
        "    p = np.random.permutation(num)\n",
        "    return [d[p] for d in data]\n",
        "\n",
        "\n",
        "def batch_generator(data, batch_size, shuffle=True):\n",
        "    \"\"\"Generate batches of data.\n",
        "    \n",
        "    Given a list of array-like objects, generate batches of a given\n",
        "    size by yielding a list of array-like objects corresponding to the\n",
        "    same slice of each input.\n",
        "    \"\"\"\n",
        "    if shuffle:\n",
        "        data = shuffle_aligned_list(data)\n",
        "\n",
        "    batch_count = 0\n",
        "    while True:\n",
        "        if batch_count * batch_size + batch_size >= len(data[0]):\n",
        "            batch_count = 0\n",
        "\n",
        "            if shuffle:\n",
        "                data = shuffle_aligned_list(data)\n",
        "\n",
        "        start = batch_count * batch_size\n",
        "        end = start + batch_size\n",
        "        batch_count += 1\n",
        "        yield [d[start:end] for d in data]\n",
        "\n",
        "\n",
        "def imshow_grid(images, shape=[2, 8]):\n",
        "    \"\"\"Plot images in a grid of a given shape.\"\"\"\n",
        "    fig = plt.figure(1)\n",
        "    grid = ImageGrid(fig, 111, nrows_ncols=shape, axes_pad=0.05)\n",
        "\n",
        "    size = shape[0] * shape[1]\n",
        "    for i in range(size):\n",
        "        grid[i].axis('off')\n",
        "        grid[i].imshow(images[i])  # The AxesGrid object work as a list of axes.\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_embedding(X, y, d, title=None):\n",
        "    \"\"\"Plot an embedding X with the class label y colored by the domain d.\"\"\"\n",
        "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
        "    X = (X - x_min) / (x_max - x_min)\n",
        "\n",
        "    # Plot colors numbers\n",
        "    plt.figure(figsize=(10,10))\n",
        "    ax = plt.subplot(111)\n",
        "    for i in range(X.shape[0]):\n",
        "        # plot colored number\n",
        "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
        "                 color=plt.cm.bwr(d[i] / 1.),\n",
        "                 fontdict={'weight': 'bold', 'size': 9})\n",
        "\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "        \n",
        "print ('Library and utility functions prepared.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_fwBxQCdFzI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ]
    },
    {
      "metadata": {
        "id": "bWOqn_oxXes0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# To prevent warning created by loading MNIST \n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "from sklearn.manifold import TSNE\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "# Process MNIST\n",
        "# Generate mnist dataset with 3 channel\n",
        "mnist_train = (mnist.train.images > 0).reshape(55000, 28, 28, 1).astype(np.uint8) * 255\n",
        "mnist_train = np.concatenate([mnist_train, mnist_train, mnist_train], 3)\n",
        "mnist_test = (mnist.test.images > 0).reshape(10000, 28, 28, 1).astype(np.uint8) * 255\n",
        "mnist_test = np.concatenate([mnist_test, mnist_test, mnist_test], 3)\n",
        "\n",
        "# Load MNIST-M\n",
        "mnistm = pkl.load(open('mnistm_data.pkl', 'rb'))\n",
        "mnistm_train = mnistm['train']\n",
        "mnistm_test = mnistm['test']\n",
        "mnistm_valid = mnistm['valid']\n",
        "\n",
        "# Compute pixel mean for normalizing data\n",
        "pixel_mean = np.vstack([mnist_train, mnistm_train]).mean((0, 1, 2))\n",
        "\n",
        "# Create a mixed dataset for TSNE visualization\n",
        "num_test = 500\n",
        "combined_test_imgs = np.vstack([mnist_test[:num_test], mnistm_test[:num_test]])\n",
        "combined_test_labels = np.vstack([mnist.test.labels[:num_test], mnist.test.labels[:num_test]])\n",
        "combined_test_domain = np.vstack([np.tile([1., 0.], [num_test, 1]),\n",
        "        np.tile([0., 1.], [num_test, 1])])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSMMjd_tdZGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Show Images Example"
      ]
    },
    {
      "metadata": {
        "id": "S8e7cApQXes9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print ('MNIST examples:')\n",
        "imshow_grid(mnist_train)\n",
        "print ('MNIST-M examples:')\n",
        "imshow_grid(mnistm_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MhYJHHZwGQze",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Show Model Architecture"
      ]
    },
    {
      "metadata": {
        "id": "6r3KCPvLcfbM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Execute this to show general DANN model ###\n",
        "from IPython.display import Image\n",
        "Image('DANN.png', width=900, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0o6YKVRsod3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Execute this to show DANN model on MNIST dataset ###\n",
        "from IPython.display import Image\n",
        "Image('MNIST_model.png', width=900, height=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U_wU05Iu8SDI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Gradient Reversal Layer\n",
        "\n",
        "TensorFlow中提供了讓使用者可以自定義gradient方法，閱讀以下程式碼需要的幾個觀念。\n",
        "\n",
        "1.   Gradient reversal layer  \n",
        "在實作上，將一層identity layer的gradient乘上一個負號，並且保持feed forward的方式不變，即為gradient reversal layer。\n",
        "\n",
        "2.   gradient_override_map     \n",
        "在TensorFlow之中有許多已定義好的運算，例如：identity, matmul等。gradient_override_map函式的輸入為一個dictionary，以一個運算的名字作為key，另一個運算的名字作為value。格式為：gradient_override_map({\"Opearation A\":\"Opearation B\" })，雙引號代表型態為string。\n",
        "這個函式會將運算A計算gradient的方法替換為運算B計算gradient的方法，並且保持運算A的feed forward的算法不變。所以我們可以自定義出一個新的運算(FlipGradient)，將它的gradient算法乘上負號，再透過gradient_override_map將identity運算的gradient算法替換成FlipGradient的gradient算法。\n",
        "\n",
        "3.   decorator @  \n",
        "由於gradient_override_map的輸入為TensorFlow之中已定義的運算名稱，因此我們需要將自定義的FlipGradient的運算名稱(型態為string)註冊到TensorFlow，完成這件事情需要使用到decorator的概念。  \n",
        "在python當中，可以函式當作輸入，輸入到其它函式或是類別(class)作操作。Decorator的作用就是將一個函式輸入到另外一個函式或類別，並將結果再assign回原來的函式，就如同它的名字：裝飾器將函式丟到另一個函式或類別裝飾一番之後，再將原本的函式取代，具體來說，Decorator的作用為：\n",
        "function(x) = decorator(function(x))  \n",
        "語法上，在函式的上面一行以@decorator_name來呼叫，範例如下：  \n",
        "```\n",
        "    @my_decorator\n",
        "    def my_func(stuff):\n",
        "        do_things()\n",
        "    以上三行的作用相當於以下三行\n",
        "    def my_func(stuff):\n",
        "        do_things()\n",
        "    my_func = my_decorator(my_func)\n",
        "```\n",
        "4.  @RegisterGradient(grad_name)  \n",
        "def _flip_gradients(op, grad):  \n",
        "用decorator將函式_flip_gradients輸入RegisterGradient這個類別，後者會將前者以\"grad_name\"這個名字註冊，註冊之後的gradient函式就會變成TensorFlow已知的運算函式，就能夠用第1點所介紹的方法，呼叫flip_gradient取代identity的gradient算法。\n",
        "\n",
        "總結這段程式碼所做的事情：註冊自定義的gradient運算、將Identity的gradient算法替換掉、將以上操作包裝成一個類別FlipGradientBuilder方便互叫。之後以將類別FlipGradientBuilder當作函式呼叫時(\\__call__)，輸入x會通過一層gradient算法自定義的Identity layer(即gradient reversal layer)，並將輸出y回傳。\n",
        "\n",
        "\n",
        "---\n",
        "Reference:\n",
        "\n",
        "register gradient:\n",
        "https://www.tensorflow.org/api_docs/python/tf/RegisterGradient\n",
        "\n",
        "operation:\n",
        "https://www.tensorflow.org/api_docs/python/tf/Operation\n",
        "\n",
        "decorator (@ symbol):\n",
        "https://blog.techbridge.cc/2018/06/15/python-decorator-introduction/\n",
        "\n",
        "gradient_override_map:\n",
        "https://stackoverflow.com/questions/41391718/tensorflows-gradient-override-map-function\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ytpFSOr3ogAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ad9d30c8-4235-4031-99f2-de2e1b1eac70"
      },
      "cell_type": "code",
      "source": [
        "### construct gradient reversal layer ###\n",
        "\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "\n",
        "class FlipGradientBuilder(object):\n",
        "    def __init__(self):\n",
        "        self.num_calls = 0\n",
        "\n",
        "    def __call__(self, x, l=1.0):\n",
        "        grad_name = \"FlipGradient%d\" % self.num_calls\n",
        "        @ops.RegisterGradient(grad_name)\n",
        "        def _flip_gradients(op, grad):\n",
        "            return [tf.negative(grad) * l]\n",
        "        \n",
        "        g = tf.get_default_graph()\n",
        "        with g.gradient_override_map({\"Identity\": grad_name}):\n",
        "            y = tf.identity(x)\n",
        "            \n",
        "        self.num_calls += 1\n",
        "        return y\n",
        "    \n",
        "flip_gradient = FlipGradientBuilder()\n",
        "\n",
        "print('Construct gradient reversal layer.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Construct gradient reversal layer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0cQRjCbSSsa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Define Model\n",
        "\n",
        "DANN的設計上有個特別之處，source domain的資料會進到label predictor和domain classifier，但target domain的資料只會進到domain classifier，TensorFlow裡的tf.cond可以幫助我們做出分流的效果，以下是它的格式，通常有3個輸入：  \n",
        "tf.cond(pred, true, false)   \n",
        "pred為判斷式，如果pred的結果為真，則選擇true回傳，反之選擇false回傳。 \n",
        "    \n",
        "另外，為了方便將source和target的資料分開，會事先將source資料放在batch的前半部，target資料放在batch的後半部。\n",
        "\n",
        "---\n",
        "Reference:  \n",
        "tf.cond:  \n",
        "https://www.tensorflow.org/api_docs/python/tf/cond  \n"
      ]
    },
    {
      "metadata": {
        "id": "xBodV6hNXetB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "class MNISTModel(object):\n",
        "    \"\"\"Simple MNIST domain adaptation model.\"\"\"\n",
        "    def __init__(self):\n",
        "        self._build_model()\n",
        "  \n",
        "    def _build_model(self):\n",
        "        \n",
        "       # image size = 28 x 28 x 3 \n",
        "        self.X = tf.placeholder(tf.uint8, [None, 28, 28, 3])\n",
        "        # number of class = 10 (0~9)\n",
        "        self.y = tf.placeholder(tf.float32, [None, 10])\n",
        "        # domain=1: mnist / domain=0: mnist-m \n",
        "        self.domain = tf.placeholder(tf.float32, [None, 2])\n",
        "        self.l = tf.placeholder(tf.float32, [])\n",
        "        self.train = tf.placeholder(tf.bool, [])\n",
        "        \n",
        "        X_input = (tf.cast(self.X, tf.float32) - pixel_mean) / 255.\n",
        "        \n",
        "        # CNN model for feature extraction (Green Part)\n",
        "        with tf.variable_scope('feature_extractor'):\n",
        "\n",
        "            W_conv0 = weight_variable([5, 5, 3, 32])\n",
        "            b_conv0 = bias_variable([32])\n",
        "            h_conv0 = tf.nn.relu(conv2d(X_input, W_conv0) + b_conv0)\n",
        "            h_pool0 = max_pool_2x2(h_conv0)\n",
        "            \n",
        "            W_conv1 = weight_variable([5, 5, 32, 48])\n",
        "            b_conv1 = bias_variable([48])\n",
        "            h_conv1 = tf.nn.relu(conv2d(h_pool0, W_conv1) + b_conv1)\n",
        "            h_pool1 = max_pool_2x2(h_conv1)\n",
        "            \n",
        "            # The domain-invariant feature\n",
        "            self.feature = tf.reshape(h_pool1, [-1, 7*7*48])\n",
        "            \n",
        "        # MLP for class prediction (Blue Part)\n",
        "        with tf.variable_scope('label_predictor'):\n",
        "            \n",
        "            # Switches to route target examples (second half of batch) differently\n",
        "            # depending on train or test mode.\n",
        "            all_features = lambda: self.feature\n",
        "            source_features = lambda: tf.slice(self.feature, [0, 0], [batch_size // 2, -1])\n",
        "            classify_feats = tf.cond(self.train, source_features, all_features)\n",
        "            \n",
        "            all_labels = lambda: self.y\n",
        "            source_labels = lambda: tf.slice(self.y, [0, 0], [batch_size // 2, -1])\n",
        "            self.classify_labels = tf.cond(self.train, source_labels, all_labels)\n",
        "            \n",
        "            W_fc0 = weight_variable([7 * 7 * 48, 100])\n",
        "            b_fc0 = bias_variable([100])\n",
        "            h_fc0 = tf.nn.relu(tf.matmul(classify_feats, W_fc0) + b_fc0)\n",
        "\n",
        "            W_fc1 = weight_variable([100, 100])\n",
        "            b_fc1 = bias_variable([100])\n",
        "            h_fc1 = tf.nn.relu(tf.matmul(h_fc0, W_fc1) + b_fc1)\n",
        "\n",
        "            W_fc2 = weight_variable([100, 10])\n",
        "            b_fc2 = bias_variable([10])\n",
        "            logits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
        "            \n",
        "            self.pred = tf.nn.softmax(logits)\n",
        "            self.pred_loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=self.classify_labels)\n",
        "\n",
        "        # Small MLP for domain prediction with adversarial loss (Pink Part)\n",
        "        with tf.variable_scope('domain_predictor'):\n",
        "            \n",
        "            # Flip the gradient when backpropagating through this operation\n",
        "            feat = flip_gradient(self.feature, self.l)\n",
        "            \n",
        "            d_W_fc0 = weight_variable([7 * 7 * 48, 100])\n",
        "            d_b_fc0 = bias_variable([100])\n",
        "            d_h_fc0 = tf.nn.relu(tf.matmul(feat, d_W_fc0) + d_b_fc0)\n",
        "            \n",
        "            d_W_fc1 = weight_variable([100, 2])\n",
        "            d_b_fc1 = bias_variable([2])\n",
        "            d_logits = tf.matmul(d_h_fc0, d_W_fc1) + d_b_fc1\n",
        "            \n",
        "            self.domain_pred = tf.nn.softmax(d_logits)\n",
        "            self.domain_loss = tf.nn.softmax_cross_entropy_with_logits(logits=d_logits, labels=self.domain)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9QNm6pyTXetE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build the model graph\n",
        "graph = tf.get_default_graph()\n",
        "with graph.as_default():\n",
        "    model = MNISTModel()\n",
        "    \n",
        "    learning_rate = tf.placeholder(tf.float32, [])\n",
        "    \n",
        "    pred_loss = tf.reduce_mean(model.pred_loss)\n",
        "    domain_loss = tf.reduce_mean(model.domain_loss)\n",
        "    total_loss = pred_loss + domain_loss\n",
        "\n",
        "    regular_train_op = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(pred_loss)\n",
        "    dann_train_op = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(total_loss)\n",
        "    \n",
        "    # Evaluation\n",
        "    correct_label_pred = tf.equal(tf.argmax(model.classify_labels, 1), tf.argmax(model.pred, 1))\n",
        "    label_acc = tf.reduce_mean(tf.cast(correct_label_pred, tf.float32))\n",
        "    correct_domain_pred = tf.equal(tf.argmax(model.domain, 1), tf.argmax(model.domain_pred, 1))\n",
        "    domain_acc = tf.reduce_mean(tf.cast(correct_domain_pred, tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yd2ZHrHu_EpB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Process\n",
        "\n",
        "Training分為三種模式：dann, source, target，一個模式training大約2分鐘。\n",
        "\n",
        "\n",
        "1.   dann  \n",
        "使用source和target domain的影像，以及source domain的標籤。\n",
        "2.   source  \n",
        "僅使用source domain的影像以及標籤。\n",
        "3.   target   \n",
        "僅使用target domain的影像以及標籤。一般來說，target domain的標籤是沒辦法取得，也不允許被使用的。這個模式使用這些標籤只是為了產生上界(upper bound)，作為對照組比較。\n"
      ]
    },
    {
      "metadata": {
        "id": "fr-0G0IiXetH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(training_mode, graph, model, num_steps=8600, verbose=False):\n",
        "    \"\"\"Helper to run the model with different training modes.\"\"\"\n",
        "\n",
        "    with tf.Session(graph=graph) as sess:\n",
        "        tf.global_variables_initializer().run()\n",
        "\n",
        "        # Batch generators\n",
        "        gen_source_batch = batch_generator(\n",
        "            [mnist_train, mnist.train.labels], batch_size // 2)\n",
        "        gen_target_batch = batch_generator(\n",
        "            [mnistm_train, mnist.train.labels], batch_size // 2)\n",
        "        gen_source_only_batch = batch_generator(\n",
        "            [mnist_train, mnist.train.labels], batch_size)\n",
        "        gen_target_only_batch = batch_generator(\n",
        "            [mnistm_train, mnist.train.labels], batch_size)\n",
        "\n",
        "        domain_labels = np.vstack([np.tile([1., 0.], [batch_size // 2, 1]),\n",
        "                                   np.tile([0., 1.], [batch_size // 2, 1])])\n",
        "\n",
        "        # Training loop\n",
        "        for i in range(num_steps):\n",
        "            \n",
        "            # Adaptation param and learning rate schedule as described in the paper\n",
        "            p = float(i) / num_steps\n",
        "            l = 2. / (1. + np.exp(-10. * p)) - 1\n",
        "            lr = 0.01 / (1. + 10 * p)**0.75\n",
        "\n",
        "            # Training step\n",
        "            if training_mode == 'dann':\n",
        "\n",
        "                X0, y0 = next(gen_source_batch)\n",
        "                X1, y1 = next(gen_target_batch)\n",
        "                X = np.vstack([X0, X1])\n",
        "                y = np.vstack([y0, y1])\n",
        "\n",
        "                _, batch_loss, dloss, ploss, d_acc, p_acc = sess.run(\n",
        "                    [dann_train_op, total_loss, domain_loss, pred_loss, domain_acc, label_acc],\n",
        "                    feed_dict={model.X: X, model.y: y, model.domain: domain_labels,\n",
        "                               model.train: True, model.l: l, learning_rate: lr})\n",
        "\n",
        "                if verbose and i % 100 == 0:\n",
        "                    print('loss: {}  d_acc: {}  p_acc: {}  p: {}  l: {}  lr: {}'.format(\n",
        "                            batch_loss, d_acc, p_acc, p, l, lr))\n",
        "\n",
        "            elif training_mode == 'source':\n",
        "                X, y = next(gen_source_only_batch)\n",
        "                _, batch_loss = sess.run([regular_train_op, pred_loss],\n",
        "                                     feed_dict={model.X: X, model.y: y, model.train: False,\n",
        "                                                model.l: l, learning_rate: lr})\n",
        "\n",
        "            elif training_mode == 'target':\n",
        "                X, y = next(gen_target_only_batch)\n",
        "                _, batch_loss = sess.run([regular_train_op, pred_loss],\n",
        "                                     feed_dict={model.X: X, model.y: y, model.train: False,\n",
        "                                                model.l: l, learning_rate: lr})\n",
        "\n",
        "        # Compute final evaluation on test data\n",
        "        source_acc = sess.run(label_acc,\n",
        "                            feed_dict={model.X: mnist_test, model.y: mnist.test.labels,\n",
        "                                       model.train: False})\n",
        "\n",
        "        target_acc = sess.run(label_acc,\n",
        "                            feed_dict={model.X: mnistm_test, model.y: mnist.test.labels,\n",
        "                                       model.train: False})\n",
        "        \n",
        "        test_domain_acc = sess.run(domain_acc,\n",
        "                            feed_dict={model.X: combined_test_imgs,\n",
        "                                       model.domain: combined_test_domain, model.l: 1.0})\n",
        "        \n",
        "        test_emb = sess.run(model.feature, feed_dict={model.X: combined_test_imgs})\n",
        "        \n",
        "    return source_acc, target_acc, test_domain_acc, test_emb\n",
        "\n",
        "\n",
        "print('\\nSource only training')\n",
        "source_acc, target_acc, _, source_only_emb = train_and_evaluate('source', graph, model)\n",
        "print('Source (MNIST) accuracy:', source_acc)\n",
        "print('Target (MNIST-M) accuracy:', target_acc)\n",
        "\n",
        "print('\\nDomain adaptation training')\n",
        "source_acc, target_acc, d_acc, dann_emb = train_and_evaluate('dann', graph, model)\n",
        "print('Source (MNIST) accuracy:', source_acc)\n",
        "print('Target (MNIST-M) accuracy:', target_acc)\n",
        "\n",
        "print('\\nTarget only training')\n",
        "source_acc, target_acc, _, source_only_emb = train_and_evaluate('target', graph, model)\n",
        "print('Source (MNIST) accuracy:', source_acc)\n",
        "print('Target (MNIST-M) accuracy:', target_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Tf967zvQDJU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualization\n",
        "\n",
        "將實驗結果視覺化，藍色數字為source domain資料的預測結果，紅色數字為target domain資料的預測結果。  \n",
        "從source模式的結果(上圖)可以看出，藍色部份的分群已非常完整，代表source domain的正確率很高，而紅色部份則比較混亂。  \n",
        "然而dann模式的結果(下圖)，藍色部份的分群保持完整，而且紅色部份的分群有顯著改善，證明DANN對target domain具有明顯改善效果。"
      ]
    },
    {
      "metadata": {
        "id": "T1aoktrgXetL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Take few minutes to visualize\n",
        "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3000)\n",
        "source_only_tsne = tsne.fit_transform(source_only_emb)\n",
        "\n",
        "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3000)\n",
        "dann_tsne = tsne.fit_transform(dann_emb)\n",
        "        \n",
        "plot_embedding(source_only_tsne, combined_test_labels.argmax(1), combined_test_domain.argmax(1), 'Source only')\n",
        "plot_embedding(dann_tsne, combined_test_labels.argmax(1), combined_test_domain.argmax(1), 'Domain Adaptation')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}